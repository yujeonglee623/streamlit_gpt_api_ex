import streamlit as st
import os
import openai
from dotenv import load_dotenv
from moviepy import VideoFileClip
import requests
import json
import csv
import io
import re
from collections import Counter

# í™”ì ë¶„ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒ)
try:
    from pyannote.audio import Pipeline
    _HAS_PYANNOTE = True
except Exception:
    _HAS_PYANNOTE = False


# ==================== ì˜¤ë””ì˜¤ ì¶”ì¶œ & ì „ì‚¬ ====================
def extract_audio(video_path, audio_path):
    """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œí•˜ì—¬ MP3 íŒŒì¼ë¡œ ì €ì¥"""
    try:
        clip = VideoFileClip(video_path)
        clip.audio.write_audiofile(audio_path, codec='mp3')
        return True
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def transcribe_audio(audio_path, client):
    """ê¸°ë³¸ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜"""
    try:
        with open(audio_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        return transcript.text
    except Exception as e:
        st.error(f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def transcribe_audio_with_timestamps(audio_path, client):
    """íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ì „ì‚¬ (ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´)"""
    try:
        with open(audio_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                timestamp_granularities=["segment"]
            )
        return transcript
    except Exception as e:
        st.error(f"íƒ€ì„ìŠ¤íƒ¬í”„ ì „ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


# ==================== íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§·íŒ… ====================
def format_timestamp(seconds):
    """ì´ˆë¥¼ HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}"


def format_transcript_with_timestamps(transcript_data):
    """íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ì „ì‚¬ ë°ì´í„°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    formatted_text = ""
    for segment in transcript_data.segments:
        start_time = format_timestamp(segment.start)
        end_time = format_timestamp(segment.end)
        text = segment.text.strip()
        formatted_text += f"[{start_time} --> {end_time}]\n{text}\n\n"
    return formatted_text


# ==================== ë²ˆì—­ ====================
def translate_text(client, text_to_translate, target_language="English"):
    """OpenAIë¡œ í…ìŠ¤íŠ¸ ë²ˆì—­"""
    if not text_to_translate:
        return None
    
    system_prompt = "You are a professional translator. Translate the given text accurately and naturally."
    user_prompt = f"Translate the following text to {target_language}:\n\n{text_to_translate}"
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


# ==================== AI ì´ë¯¸ì§€ ìƒì„± ====================
def summarize_script_for_image(client, script_text):
    """ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ë¡œ ìš”ì•½"""
    if not script_text:
        return "A blank canvas."
    
    summary_prompt = (
        f"Summarize the following video transcript into a concise, descriptive sentence "
        f"that would be ideal for generating an illustrative image. "
        f"Focus on the main subject, action, and setting. Keep it under 20 words.\n\n"
        f"Transcript: {script_text[:1000]}"
    )
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that summarizes text for image generation."},
                {"role": "user", "content": summary_prompt}
            ],
            max_tokens=50
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}")
        return "An abstract representation of a video."


def generate_image_from_text(client, prompt_text, image_path):
    """DALL-Eë¡œ ì´ë¯¸ì§€ ìƒì„±"""
    try:
        st.info(f"ğŸ¨ AI ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸: '{prompt_text}'")
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt_text,
            size="1024x1024",
            quality="standard",
            n=1,
        )
        image_url = response.data[0].url
        
        img_data = requests.get(image_url).content
        with open(image_path, 'wb') as handler:
            handler.write(img_data)
        
        return image_path
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None


# ==================== í‚¤ì›Œë“œ ì¶”ì¶œ ====================
def extract_keywords(text, client, top_k=10, language="ko"):
    """
    LLMì„ í™œìš©í•´ í•µì‹¬ í‚¤ì›Œë“œë¥¼ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    í™˜ê²½ë³€ìˆ˜ KEYWORD_MODEL (ê¸°ë³¸: gpt-4o-mini)
    ì‹¤íŒ¨ ì‹œ keyword_fallbackìœ¼ë¡œ ëŒ€ì²´.
    """
    model = os.getenv("KEYWORD_MODEL", "gpt-4o-mini")
    prompt = (
        "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ê°œë…ì„ ë½‘ì•„ë‚´ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤. "
        "ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ {} ì–¸ì–´ë¡œ ìƒìœ„ {}ê°œë§Œ ì—„ë°€í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”. "
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ë°°ì—´(list) í˜•ì‹ìœ¼ë¡œë§Œ, ê° ìš”ì†ŒëŠ” stringìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”. "
        "í•´ì‹œíƒœê·¸, ì£¼ì„, ì„¤ëª…ë¬¸ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•©ë‹ˆë‹¤."
    ).format("í•œêµ­ì–´" if language.startswith("ko") else language, top_k)

    # ì…ë ¥ì´ ë„ˆë¬´ ê¸¸ ê²½ìš° ì•/ë’¤ ì¼ë¶€ë§Œ ê²°í•©
    max_chars = 12000
    if len(text) > max_chars:
        head = text[:6000]
        tail = text[-6000:]
        text_for_llm = head + "\n...\n" + tail
    else:
        text_for_llm = text

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "Return only valid JSON."},
                {"role": "user", "content": prompt + "\n\n[ìŠ¤í¬ë¦½íŠ¸]\n" + text_for_llm}
            ],
            temperature=0.2,
        )
        raw = resp.choices[0].message.content.strip()
        # JSONë§Œ ì¶”ì¶œ ì‹œë„
        json_str = extract_json_block(raw)
        keywords = json.loads(json_str)
        # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ ë³´ì¥
        keywords = [str(k).strip() for k in keywords if isinstance(k, (str, int, float))]
        # ê³ ìœ í™” ë° ìƒìœ„ k ì œí•œ
        seen = set()
        uniq = []
        for k in keywords:
            if k not in seen and k != "":
                uniq.append(k)
                seen.add(k)
        return uniq[:top_k] if top_k else uniq
    except Exception:
        # ì‹¤íŒ¨ ì‹œ ë°±ì—… ë¡œì§
        return keyword_fallback(text, top_k=top_k, language=language)


def extract_json_block(s: str) -> str:
    """ì‘ë‹µì—ì„œ JSON ë°°ì—´ ë¶€ë¶„ë§Œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ."""
    s = s.strip()
    # code fence ì•ˆì˜ JSON ìš°ì„  íƒìƒ‰
    fence = re.search(r"```(?:json)?\s*(\[[\s\S]*?\])\s*```", s, flags=re.IGNORECASE)
    if fence:
        return fence.group(1).strip()
    # ì „ì²´ì—ì„œ ëŒ€ê´„í˜¸ ë¸”ë¡ íƒìƒ‰
    arr = re.search(r"\[[\s\S]*\]", s)
    if arr:
        return arr.group(0).strip()
    # ë§ˆì§€ë§‰ ì‹œë„: ê·¸ëŒ€ë¡œ ë°˜í™˜ (íŒŒì‹± ì‹œ ì—ëŸ¬ ë‚˜ë©´ fallback)
    return s


def keyword_fallback(text, top_k=10, language="ko"):
    """
    ê°„ë‹¨í•œ ë¹ˆë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (í˜•íƒœì†Œ ë¶„ì„ê¸° ì—†ì´ ëŒ€ëµì ).
    - ì˜ë¬¸/ìˆ«ì/í•œê¸€ ë‹¨ì–´ í† í°í™”
    - ê¸¸ì´ 2 ì´ìƒ & í”í•œ ë¶ˆìš©ì–´ ì œê±°
    """
    # í† í°í™”: í•œê¸€/ì˜ë¬¸/ìˆ«ì
    tokens = re.findall(r"[A-Za-z0-9ê°€-í£]+", text)
    # ì†Œë¬¸ì
    tokens = [t.lower() for t in tokens]

    stop_ko = set("""ê·¸ë¦¬ê³  ê·¸ëŸ¬ë‚˜ ê·¸ë˜ì„œ ë˜í•œ ë˜í•œì€ ë˜ëŠ” ë˜ëŠ”ì€ ë° ë“±ì´ ì´ëŸ° ê·¸ëŸ° ì €ëŸ° ë§¤ìš° ë„ˆë¬´ ì •ë§ ê·¸ëƒ¥ ë°”ë¡œ ì´ì œ ë˜í•œ ì¦‰ ë‹¤ì‹œ ë˜í•œì˜ ëŒ€í•œ ëŒ€í•œì˜ 
        ê²½ìš° ì´ëŸ°ì €ëŸ° í•˜ëŠ” í•˜ëŠ”ë° í•˜ëŠ”ë°ìš” í•˜ëŠ”ê±¸ í•˜ëŠ”ê±° í•˜ëŠ”ê²ƒ ì´ëŸ°ê²ƒ ì €ëŸ°ê²ƒ ê·¸ëŸ°ê²ƒ ì´ê²ƒ ì €ê²ƒ ê·¸ê²ƒ ê·¸ëŸ° ì´ ê·¸ ì € ë­ ë­ì§€ ë­ëƒ ì™œ ì–´ë–»ê²Œ ëˆ„êµ¬ ì–´ë”” ì–¸ì œ 
        ìˆë‹¤ ì—†ë‹¤ ë˜ë‹¤ í•˜ë‹¤ ì´ë‹¤ ì•„ë‹ˆë‹¤ ë§ì€ ë§ì€ë° ê°™ì€ ê°™ì€ë° í•´ë‹¹ í•´ë‹¹ì˜ í•´ë‹¹ë¨ í¬í•¨ í¬í•¨í•œ í¬í•¨í•˜ì—¬ í¬í•¨í•´ì„œ ëŒ€í•œ ëŒ€í•´ ëŒ€í•´ì„  ëŒ€í•´ì„ ìš” ëŒ€í•œê±°
        ë“± ë“±ë“± ë“±ì˜ ë¡œ ë¡œì„œ ìœ¼ë¡œ ìœ¼ë¡œì„œ ìœ¼ë¡œì¨ ì— ì—ì„œ ì—ê²Œ ì™€ ê³¼ ì˜ ëŠ” ì€ ê°€ ì´ ì„ ë¥¼ ë„ ë§Œ ë¡œë¶€í„° ë¶€í„° ê¹Œì§€""".split())
    stop_en = set("""
        the a an and or of for in on to with from as is are was were be been being that this these those it its by at if then
        so such very just also more most much many any some no not but into over under out up down off about can could should would
    """.split())

    filtered = [t for t in tokens if len(t) >= 2 and t not in stop_ko and t not in stop_en]
    freq = Counter(filtered)
    # ìˆ«ì/ë‹¨ìˆœ ìˆ«ìì—´ ì œì™¸
    items = [(w, c) for w, c in freq.most_common() if not w.isdigit()]
    top = [w for w, _ in items[:top_k]]
    return top


def keywords_to_csv_bytes(keywords):
    """í‚¤ì›Œë“œë¥¼ CSV ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
    buf = io.StringIO()
    writer = csv.writer(buf)
    writer.writerow(["rank", "keyword"])
    for i, kw in enumerate(keywords, 1):
        writer.writerow([i, kw])
    return buf.getvalue().encode("utf-8-sig")


def keywords_to_json_bytes(keywords):
    """í‚¤ì›Œë“œë¥¼ JSON ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
    return json.dumps({"keywords": keywords}, ensure_ascii=False, indent=2).encode("utf-8")

# ==================== íŒŒì¼ ì €ì¥ ====================
def save_file(content, filename):
    """í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)


# ==================== MAIN ====================
def main():
    load_dotenv(override=True)
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    client = openai.OpenAI(api_key=api_key)
    
    st.title("ğŸ¥ í†µí•© ë¹„ë””ì˜¤ AI ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    st.markdown("*ë¹„ë””ì˜¤ â†’ ì˜¤ë””ì˜¤ ì¶”ì¶œ â†’ ì „ì‚¬ â†’ ë²ˆì—­ â†’ ì´ë¯¸ì§€ ìƒì„± â†’ í‚¤ì›Œë“œ ì¶”ì¶œ*")
    
    # ì˜µì…˜ ì„ íƒ
    col1, col2, col3 = st.columns(3)
    with col1:
        include_timestamps = st.checkbox("â±ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨", value=False)
    with col2:
        enable_translation = st.checkbox("ğŸŒ ì˜ì–´ ë²ˆì—­", value=True)
    with col3:
        enable_image_gen = st.checkbox("ğŸ–¼ï¸ AI ì´ë¯¸ì§€ ìƒì„±", value=False)
    
    uploaded_file = st.file_uploader("ë¹„ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ", type=["mp4", "mov", "avi", "mkv"])
    
    if uploaded_file is not None:
        temp_dir = "temp_files"
        os.makedirs(temp_dir, exist_ok=True)
        
        video_path = os.path.join(temp_dir, uploaded_file.name)
        with open(video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        audio_path = os.path.join(temp_dir, "extracted_audio.mp3")
        script_path = os.path.join(temp_dir, "transcribed_script.txt")
        translated_script_path = os.path.join(temp_dir, "translated_script.txt")
        video_thumbnail_path = os.path.join(temp_dir, "video_thumbnail.png")
        
        # === 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ ===
        with st.spinner("1ï¸âƒ£ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘..."):
            audio_extracted = extract_audio(video_path, audio_path)
        
        if not audio_extracted:
            st.error("âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨")
            return
        
        st.success("âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ")
        st.audio(audio_path, format='audio/mp3')
        
        # === 2. ìŒì„± â†’ í…ìŠ¤íŠ¸ ===
        with st.spinner("2ï¸âƒ£ ìŒì„± ë³€í™˜ ì¤‘..."):
            if include_timestamps:
                transcript_data = transcribe_audio_with_timestamps(audio_path, client)
                script_text = format_transcript_with_timestamps(transcript_data) if transcript_data else None
            else:
                script_text = transcribe_audio(audio_path, client)
        
        if not script_text:
            st.error("âŒ ìŒì„± ë³€í™˜ ì‹¤íŒ¨")
            return
        
        st.success("âœ… ìŒì„± ë³€í™˜ ì™„ë£Œ")
        save_file(script_text, script_path)
        
        # === 3. ë²ˆì—­ ===
        translated_text = None
        if enable_translation:
            with st.spinner("3ï¸âƒ£ ì˜ì–´ ë²ˆì—­ ì¤‘..."):
                translated_text = translate_text(client, script_text)
            if translated_text:
                st.success("âœ… ë²ˆì—­ ì™„ë£Œ")
                save_file(translated_text, translated_script_path)
        
        # === 4. AI ì´ë¯¸ì§€ ìƒì„± ===
        generated_image_path = None
        if enable_image_gen:
            st.markdown("---")
            with st.spinner("4ï¸âƒ£ ë¹„ë””ì˜¤ ëŒ€í‘œ ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
                image_prompt = summarize_script_for_image(client, script_text)
                generated_image_path = generate_image_from_text(client, image_prompt, video_thumbnail_path)
            
            if generated_image_path:
                st.success("âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
                st.image(generated_image_path, caption="AI ìƒì„± ëŒ€í‘œ ì´ë¯¸ì§€", use_column_width=True)
        
        # === 5. í‚¤ì›Œë“œ ì¶”ì¶œ ===
        st.markdown("---")
        st.subheader("ğŸ§  í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ")
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            top_k = st.number_input("í‚¤ì›Œë“œ ê°œìˆ˜", min_value=3, max_value=30, value=10, step=1)
        with col2:
            lang = st.selectbox("ì–¸ì–´", ["ko", "en"], index=0)
        with col3:
            use_llm = st.checkbox("LLM ì‚¬ìš©(ì •êµ, ìœ ë£Œ)", value=True, help="ì²´í¬ í•´ì œ ì‹œ ê°„ë‹¨ ë¹ˆë„ ê¸°ë°˜ ì¶”ì¶œ")
        
        if st.button("í‚¤ì›Œë“œ ì¶”ì¶œ"):
            with st.spinner("í‚¤ì›Œë“œ ë¶„ì„ ì¤‘..."):
                if use_llm:
                    keywords = extract_keywords(script_text, client, top_k=int(top_k), language=lang)
                else:
                    keywords = keyword_fallback(script_text, top_k=int(top_k), language=lang)
            
            if keywords:
                st.success("âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
                
                # íƒœê·¸ì²˜ëŸ¼ í‘œì‹œ
                st.markdown("**Top Keywords:** " + " Â· ".join([f"`{k}`" for k in keywords]))
                
                # í…Œì´ë¸” í‘œì‹œ
                st.write({"rank": list(range(1, len(keywords)+1)), "keyword": keywords})
                
                # ë‹¤ìš´ë¡œë“œ
                csv_bytes = keywords_to_csv_bytes(keywords)
                json_bytes = keywords_to_json_bytes(keywords)
                
                col_k1, col_k2 = st.columns(2)
                with col_k1:
                    st.download_button("ğŸ“¥ í‚¤ì›Œë“œ CSV", csv_bytes, "keywords.csv", mime="text/csv")
                with col_k2:
                    st.download_button("ğŸ“¥ í‚¤ì›Œë“œ JSON", json_bytes, "keywords.json", mime="application/json")
            else:
                st.warning("í‚¤ì›Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # === ê²°ê³¼ í‘œì‹œ ===
        st.markdown("---")
        st.subheader("ğŸ“ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸")
        st.text_area("korean_script", script_text, height=200, label_visibility="collapsed")
        
        if translated_text:
            st.subheader("ğŸŒ ë²ˆì—­ ìŠ¤í¬ë¦½íŠ¸ (English)")
            st.text_area("english_script", translated_text, height=200, label_visibility="collapsed")
        
        # === ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ===
        st.markdown("---")
        st.subheader("ğŸ“¥ ë‹¤ìš´ë¡œë“œ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            with open(audio_path, 'rb') as f_audio:
                st.download_button("ğŸµ ì˜¤ë””ì˜¤", f_audio, "audio.mp3", mime="audio/mp3")
        
        with col2:
            st.download_button("ğŸ“„ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸", script_text, "script_kr.txt", mime="text/plain")
        
        if translated_text:
            with col3:
                st.download_button("ğŸŒ ë²ˆì—­ ìŠ¤í¬ë¦½íŠ¸", translated_text, "script_en.txt", mime="text/plain")
        
        # === ë‹¤ì–‘í•œ í¬ë§· ë‚´ë³´ë‚´ê¸° ===
        st.markdown("---")
        st.subheader("ğŸ“¤ ë‹¤ì–‘í•œ í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°")
        
        export_type = st.selectbox("í¬ë§· ì„ íƒ", ["Text (.txt)", "Markdown (.md)", "CSV (.csv)"])
        
        if st.button("ì„ íƒí•œ í¬ë§·ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"):
            if export_type == "Text (.txt)":
                st.download_button("ğŸ“¥ TXT ë‹¤ìš´ë¡œë“œ", script_text, "transcript.txt", mime="text/plain")
            elif export_type == "Markdown (.md)":
                md_content = f"# Video Transcript\n\n{script_text}"
                st.download_button("ğŸ“¥ MD ë‹¤ìš´ë¡œë“œ", md_content, "transcript.md", mime="text/markdown")
            elif export_type == "CSV (.csv)":
                csv_content = 'timestamp,text\n0:00:00,"' + script_text.replace('"', '""') + '"'
                st.download_button("ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ", csv_content, "transcript.csv", mime="text/csv")


if __name__ == "__main__":
    main()